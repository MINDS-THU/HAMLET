import sys
from pathlib import Path
import re
import os
import shutil
import time
import threading
from typing import Optional
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

from dotenv import load_dotenv
load_dotenv()

import gradio as gr
import uuid
import tempfile
import atexit
import pandas as pd
from gradio_pdf import PDF

# Add project root to sys.path to allow for relative imports
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Configure a writable temp/cache directory for Gradio to avoid /tmp permission issues
try:
    gradio_temp_dir = project_root / "gradio_temp"
    gradio_temp_dir.mkdir(exist_ok=True)
    # Environment variable respected by Gradio for temp storage
    os.environ["GRADIO_TEMP_DIR"] = str(gradio_temp_dir)
    # Older versions may also look at GRADIO_CACHE_DIR
    os.environ.setdefault("GRADIO_CACHE_DIR", str(gradio_temp_dir))
    print(f"[GRADIO] Using custom temp dir: {gradio_temp_dir}")
except Exception as e:
    print(f"[GRADIO] Failed to set custom temp dir: {e}")

from hamlet.serve.agent_config_ui import AgentConfigManager, stream_to_gradio
from hamlet.core.models import LiteLLMModel
from hamlet.core.tools import Tool
from hamlet.core.monitoring import LogLevel
from hamlet.core.agents import CodeAgent
from hamlet.tools import get_available_tools, create_tool_instance, discover_tools
from hamlet.tools.text_web_browser.text_web_browser import SimpleTextBrowser

# Initialize the configuration manager for agents and tools
config_manager = AgentConfigManager()

# Retention (in seconds) for temporary ZIP bundles generated for download
BUNDLE_RETENTION_SECONDS = 60  # Adjust if you want bundles to persist longer

class FileWatcher:
    """A simple file system watcher using watchdog."""
    def __init__(self):
        self.observer = None
        self.event_handler = None
        self.callback = None
        
    def start_watching(self, directory: str, callback):
        """Start watching a directory for changes."""
        try:
            # Stop any existing watcher
            self.stop_watching()
            
            self.callback = callback
            self.event_handler = FileChangeHandler(callback)
            self.observer = Observer()
            self.observer.schedule(self.event_handler, directory, recursive=True)
            self.observer.start()
            print(f"Started watching directory: {directory}")
        except Exception as e:
            print(f"Error starting file watcher: {e}")
            # Create a dummy watcher that doesn't crash
            self.observer = None
    
    def stop_watching(self):
        """Stop the file watcher."""
        if self.observer:
            try:
                self.observer.stop()
                self.observer.join()
            except Exception as e:
                print(f"Error stopping file watcher: {e}")
            finally:
                self.observer = None
    
    def __del__(self):
        """Cleanup when object is destroyed."""
        self.stop_watching()

class FileChangeHandler(FileSystemEventHandler):
    """Handles file system events."""
    def __init__(self, callback):
        self.callback = callback
        self.last_event_time = 0
        
    def on_any_event(self, event):
        """Handle any file system event with debouncing."""
        current_time = time.time()
        # Debounce events - only trigger callback every 0.5 seconds
        if current_time - self.last_event_time > 0.5:
            self.last_event_time = current_time
            if self.callback:
                try:
                    self.callback()
                except Exception as e:
                    print(f"Error in file watcher callback: {e}")

# Initialize the file watcher
file_watcher = FileWatcher()

def test_api_key():
    """Test if the OpenAI API key is working."""
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return False, "OPENAI_API_KEY not found in environment variables"
        
        # Basic validation of API key format
        if not api_key.startswith("sk-"):
            return False, "API key format appears invalid (should start with 'sk-')"
        
        if len(api_key) < 20:
            return False, "API key appears too short"
        
        # Skip the actual API call test for now to avoid hanging
        # We'll let the LiteLLMModel handle the validation
        return True, "API key format looks valid (skipping network test to avoid hanging)"
        
    except Exception as e:
        return False, f"API key validation failed: {str(e)}"

class ToolFactory:
    """A factory to create tool instances from their names using dynamic discovery.

    Improvements:
    - Only pass working_dir to file / KB tools.
    - Provide a shared SimpleTextBrowser instance to browser tools so they are initialized (avoids '[visit_page] Browser not initialized.')
    - Retry constructor without working_dir on TypeError.
    - Inject API keys for search tools automatically.
    """

    _shared_browser = None
    _kb_indexers = {}

    @staticmethod
    def _get_repo_indexer() -> Optional[object]:  # late import to avoid startup cost
        """Return (and lazily create) a singleton RepoIndexer for the global knowledge base.

        Current strategy: one shared knowledge base rooted at ./knowledge_base with its
        vector store kept as a SIBLING directory ./vector_store (NOT nested inside
        knowledge_base) to make it clear the embedding index is an artifact and to
        avoid accidental deletion when users clean or replace the knowledge_base
        folder. This keeps KB content & index stable across user sessions while
        working directories remain per-session.

        If initialization fails (e.g. missing embedding key / network), a None is cached
        so we don't retry repeatedly; tools that depend on the indexer will become
        placeholders with an explanatory message.
        """
        kb_root = os.path.abspath("knowledge_base")
        os.makedirs(kb_root, exist_ok=True)
        key = kb_root
        if key in ToolFactory._kb_indexers:
            return ToolFactory._kb_indexers[key]
        try:
            from hamlet.tools.kb_repo_management.repo_indexer import RepoIndexer  # local import
            # Place vector store as sibling of knowledge_base (project_root/vector_store)
            index_dir = Path(kb_root).parent / "vector_store"
            index_dir.mkdir(exist_ok=True)
            api_key = os.getenv("OPENAI_API_KEY_EMBEDDINGS") or os.getenv("OPENAI_API_KEY")
            ri = RepoIndexer(
                root=kb_root,
                watch=False,
                index_dir=index_dir,
                openai_api_key=api_key or "",  # RepoIndexer internally probes embeddings; empty triggers env fallback
            )
            ToolFactory._kb_indexers[key] = ri
            print(f"[ToolFactory] RepoIndexer initialized for KB root: {kb_root} | index_dir: {index_dir}")
            return ri
        except Exception as e:
            print(f"[ToolFactory] Failed to initialize RepoIndexer (will use stub): {e}")
            class _StubIndexer:
                def __init__(self, root):
                    self.root = Path(root)
                def update_file(self, *_a, **_k):
                    pass
                def get_query_results(self, query: str, k: int = 3):
                    return f"[StubIndexer] Semantic search unavailable (no embeddings). Query='{query}'"
                def get_unique_query_results(self, query: str, k: int = 3):
                    return self.get_query_results(query, k)
            stub = _StubIndexer(kb_root)
            ToolFactory._kb_indexers[key] = stub
            return stub

    @staticmethod
    def create_tool(tool_name: str, working_dir: str = "working_directory") -> Optional[Tool]:
        print(f"Creating tool: {tool_name} with working_dir: {working_dir}")
        # Classification sets
        file_tools = {
            'list_dir', 'see_file', 'see_text_file', 'read_binary_as_markdown', 'modify_file',
            'create_file_with_content', 'search_keyword', 'delete_file_or_folder', 'load_object_from_python_file',
            'get_paper_from_url'
        }
        kb_tools = {
            'delete_from_knowledge_base', 'list_knowledge_base_directory', 'move_or_rename_in_knowledge_base',
            'see_knowledge_base_file', 'append_to_knowledge_base_file', 'copy_to_knowledge_base',
            'write_to_knowledge_base', 'copy_from_knowledge_base', 'keyword_search_knowledge_base',
            'semantic_search_knowledge_base'
        }
        browser_tools = {
            'visit_page', 'page_up', 'page_down', 'find_on_page_ctrl_f', 'find_next',
            'download_file', 'find_archived_url', 'simple_web_search'
        }

        ctor_kwargs: dict = {}
        # working dir only for local file tools; KB tools handle working_dir selectively
        if tool_name in file_tools:
            ctor_kwargs['working_dir'] = working_dir

        # Inject RepoIndexer for KB tools
        if tool_name in kb_tools:
            repo_indexer = ToolFactory._get_repo_indexer()
            if repo_indexer is None:
                print(f"[ToolFactory] WARNING: RepoIndexer unavailable; creating placeholder for {tool_name}.")
            else:
                ctor_kwargs['repo_indexer'] = repo_indexer
                # Only the copy in/out tools also expect a working_dir parameter
                if tool_name in {'copy_to_knowledge_base', 'copy_from_knowledge_base'}:
                    ctor_kwargs['working_dir'] = working_dir

        # Shared browser (lazy)
        if tool_name in browser_tools:
            if ToolFactory._shared_browser is None:
                try:
                    serp_key = os.getenv('SERPAPI_KEY') or os.getenv('SERPAPI_API_KEY') or None
                    ToolFactory._shared_browser = SimpleTextBrowser(
                        downloads_folder=os.path.join(working_dir, 'downloads'),
                        serpapi_key=serp_key
                    )
                    print('[ToolFactory] Created shared SimpleTextBrowser.')
                except Exception as e:
                    print(f"[ToolFactory] Failed to create shared browser: {e}")
            ctor_kwargs['browser'] = ToolFactory._shared_browser

        # API key injections
        if tool_name == 'web_search':
            serper_key = os.getenv('SERPER_API_KEY') or os.getenv('SERPER_APIKEY') or os.getenv('SERPER_KEY')
            if serper_key:
                ctor_kwargs['serper_api_key'] = serper_key
            jina_key = os.getenv('JINA_API_KEY')
            if jina_key and 'reranker' not in ctor_kwargs:
                ctor_kwargs['reranker'] = 'jina'
        elif tool_name == 'simple_web_search':
            serp_key = os.getenv('SERPAPI_KEY') or os.getenv('SERPAPI_API_KEY')
            if serp_key:
                ctor_kwargs['serpapi_key'] = serp_key

        def _attempt(kwargs):
            return create_tool_instance(tool_name, **kwargs)

        try:
            try:
                tool = _attempt(ctor_kwargs)
            except TypeError as te:
                te_msg = str(te)
                # Case 1: working_dir was provided but not accepted -> retry without it
                if 'working_dir' in ctor_kwargs and ('working_dir' in te_msg or 'unexpected keyword argument' in te_msg):
                    removed = ctor_kwargs.pop('working_dir')
                    print(f"[ToolFactory] Retrying {tool_name} without working_dir={removed} due to TypeError: {te_msg}")
                    tool = _attempt(ctor_kwargs)
                # Case 2: missing required working_dir arg (not passed initially) -> inject and retry
                elif 'working_dir' not in ctor_kwargs and ('missing required positional argument' in te_msg and 'working_dir' in te_msg):
                    ctor_kwargs['working_dir'] = working_dir
                    print(f"[ToolFactory] Retrying {tool_name} adding working_dir due to TypeError: {te_msg}")
                    tool = _attempt(ctor_kwargs)
                else:
                    raise

            if hasattr(tool, 'setup'):
                try:
                    tool.setup()
                except Exception as e:
                    print(f"[ToolFactory] Setup for {tool_name} failed: {e}")

            if not hasattr(tool, 'name') or tool.name is None:
                tool.name = tool_name
                print(f"Fixed missing name for tool: {tool_name}")
            if not hasattr(tool, 'inputs'):
                tool.inputs = {"input": {"type": "string", "description": f"Input for {tool_name}"}}
                print(f"Added missing inputs for tool: {tool_name}")
            if not hasattr(tool, 'output_type'):
                tool.output_type = 'string'
                print(f"Added missing output_type for tool: {tool_name}")

            # Extra validation / diagnostics for KB tools producing base Tool behavior
            if tool_name in kb_tools and type(tool).__name__ == 'Tool':
                print(f"[ToolFactory][WARN] KB tool '{tool_name}' instantiated as base Tool (likely constructor mismatch). Kwargs used: {ctor_kwargs}")
            return tool
        except ValueError as e:
            print(f"Tool '{tool_name}' not found: {e}")
            placeholder = Tool(
                name=tool_name,
                description=f"Placeholder for unknown tool: {tool_name}",
                func=lambda x, tn=tool_name: f"[{tn}] Tool not available - placeholder executed with: {x}"
            )
            placeholder.inputs = {"input": {"type": "string", "description": f"Input for placeholder {tool_name}"}}
            placeholder.output_type = 'string'
            return placeholder
        except Exception as e:
            print(f"Error creating tool {tool_name}: {e}. Placeholder created.")
            err_tool = Tool(
                name=tool_name,
                description=f"Error placeholder for {tool_name}",
                func=lambda x, tn=tool_name: f"[{tn}] Error creating tool - placeholder executed with: {x}"
            )
            err_tool.inputs = {"input": {"type": "string", "description": f"Input for error placeholder {tool_name}"}}
            err_tool.output_type = 'string'
            return err_tool

def build_agent(name: str, system_prompt: str, tools: list, sub_agents: list, agent_type: str = "CodeAgent", working_dir: Optional[str] = None, description: str = ""):
    """Recursively builds a multi-step agent from its configuration.

    Parameters:
        name: Display / logical name of the agent.
        system_prompt: User-specified system prompt (will be APPENDED to existing agent.system_prompt after instantiation).
        tools: List of tool names.
        sub_agents: List of sub-agent names.
        agent_type: 'ToolCallingAgent' or 'CodeAgent'.
        working_dir: Working directory path for file operations.
        description: Human readable description to set on the agent (shown in UI).
    """
    if working_dir is None:
        working_dir = os.path.abspath("working_directory")

    # Sanitize agent name
    sanitized_name = re.sub(r'[^a-zA-Z0-9_]', '_', name.strip())
    if sanitized_name and sanitized_name[0].isdigit():
        sanitized_name = 'agent_' + sanitized_name
    if not sanitized_name or sanitized_name == '_':
        sanitized_name = 'unnamed_agent'

    print(f"Original name: '{name}' -> Sanitized name: '{sanitized_name}'")
    print(f"Building agent with working directory: {working_dir}")

    # Force refresh tool discovery to avoid stale cache after code edits
    try:
        discover_tools(force_refresh=True)
    except Exception as e:
        print(f"[build_agent] Tool rediscovery failed: {e}")

    tool_objs: list[Tool] = []
    for tool_name in tools:
        if not tool_name:
            continue
        try:
            tool = ToolFactory.create_tool(tool_name, working_dir)
            if tool is not None:
                if not hasattr(tool, 'name') or tool.name is None:
                    tool.name = tool_name
                    print(f"Fixed missing name for tool: {tool_name}")
                if not hasattr(tool, 'description'):
                    tool.description = f"Tool for {tool_name}"
                tool_objs.append(tool)
                print(f"Successfully created tool: {tool.name}")
            else:
                print(f"Warning: Failed to create tool {tool_name}")
        except Exception as e:
            print(f"Error creating tool {tool_name}: {e}")
            fallback_tool = Tool(
                name=tool_name,
                description=f"Fallback tool for {tool_name}",
                func=lambda x, tn=tool_name: f"[{tn}] Executed with: {x}"
            )
            fallback_tool.inputs = {
                "input": {"type": "string", "description": f"Input for {tool_name}"}
            }
            fallback_tool.output_type = "string"
            tool_objs.append(fallback_tool)

    sub_agent_objs = []
    for sa_name in sub_agents:
        md = config_manager.get_all_agent_metadata().get(sa_name, {})
        sub_agent_objs.append(build_agent(
            name=sa_name,
            system_prompt=md.get("prompt", ""),
            tools=md.get("tools", []),
            sub_agents=md.get("sub_agents", []),
            agent_type=md.get("agent_type", "CodeAgent"),
            working_dir=working_dir,
            description=md.get("description", "")
        ))

    AgentClass = CodeAgent
    try:
        print("Creating LiteLLMModel...")
        model = LiteLLMModel(
            model_id="gpt-4.1",
            timeout=30
        )
        print("LiteLLMModel instantiated successfully")
    except Exception as e:
        raise Exception(f"Failed to instantiate LiteLLMModel. Network timeout or API key issue. Error: {e}")

    print(f"Creating agent {sanitized_name} (original: {name}) with {len(tool_objs)} tools")
    for tool in tool_objs:
        print(f"  - Tool: {getattr(tool, 'name', 'UNNAMED')} (type: {type(tool).__name__})")

    print("Creating agent instance...")
    agent = AgentClass(
        tools=tool_objs,
        model=model,
        managed_agents=sub_agent_objs,
        verbosity_level=LogLevel.DEBUG,
        planning_interval=3,
        max_steps=30,
        name=sanitized_name,
        description=description or f"A {agent_type} agent with {len(tool_objs)} tools."
    )
    print(f"Agent instance created successfully with name: {sanitized_name}")
    # Preserve original (may contain non-ASCII characters) for UI display
    try:
        agent.display_name = name  # type: ignore[attr-defined]
    except Exception:
        pass

    # Append user system prompt AFTER instantiation
    try:
        if system_prompt:
            base_sp = getattr(agent, 'system_prompt', '') or ''
            new_sp = (base_sp.rstrip() + "\n" + system_prompt.strip()).strip()
            agent.system_prompt = new_sp
            print(f"Appended system prompt for agent {sanitized_name}. Length now: {len(agent.system_prompt)}")
    except Exception as e:
        print(f"Failed to append system prompt for {sanitized_name}: {e}")

    # Ensure description attribute matches provided description (redundant safety)
    try:
        if description:
            agent.description = description
    except Exception as e:
        print(f"Failed to set description for {sanitized_name}: {e}")

    # (Removed) previously appended sub-agent descriptions manually; now rely on underlying framework behavior.
    # Inject simple callable wrappers for each tool so that within code execution
    # a user can call tool_name(arg1, ...) instead of needing agent.run or manual forward.
    try:
        wrapper_count = 0
        for t in tool_objs:
            tname = getattr(t, 'name', None)
            if not tname or not isinstance(tname, str):
                continue
            # Skip if name not a valid identifier (avoid exec issues)
            if not re.match(r'^[A-Za-z_][A-Za-z0-9_]*$', tname):
                continue
            # Create a small wrapper function capturing the tool
            def _make_wrapper(tool_ref):  # closure factory
                def _wrapper(*args, **kwargs):
                    # Prefer forward if available, else fallback to callable interface
                    if hasattr(tool_ref, 'forward'):
                        try:
                            return tool_ref.forward(*args, **kwargs)
                        except TypeError:
                            # Some tools expect named args; fallback to passing first positional as 'input'
                            if len(args) == 1 and not kwargs and 'input' in getattr(tool_ref, 'inputs', {}):
                                return tool_ref.forward(args[0])  # type: ignore
                            raise
                    # Fallback: if Tool base exposes a func attribute
                    func_attr = getattr(tool_ref, 'func', None)
                    if callable(func_attr):
                        return func_attr(*args, **kwargs)
                    return f"[{tname}] Tool not callable."
                return _wrapper
            wrapper = _make_wrapper(t)
            # Attach to agent namespace (if CodeAgent supports custom locals)
            try:
                # For CodeAgent, maintain an execution namespace attribute
                existing = getattr(agent, '_exec_namespace', None)
                if existing is None:
                    existing = {}
                    setattr(agent, '_exec_namespace', existing)
                existing[tname] = wrapper
                wrapper_count += 1
            except Exception as e:
                print(f"Failed to inject wrapper for tool {tname}: {e}")
        if wrapper_count:
            print(f"Injected {wrapper_count} tool wrappers into agent execution namespace.")
    except Exception as e:
        print(f"Wrapper injection error: {e}")

    return agent
    
    # Unreachable (return above) -- keep logic below if future refactor moves return.

    # Inject callable wrappers (this block currently unreachable due to early return)
    # Keeping for reference.


def app():
    """Main function to create and configure the Gradio application.

    Updated behavior:
    - Each user/session receives an isolated temporary working directory that is NOT selectable.
    - When the browser session ends (or app exits), the directory is cleaned up.
    - Agent configurations are per-user: a user identifier is derived from Gradio's request headers / cookies.
    - The previous manual directory picker UI is removed.
    """
    # Mapping session -> temp directory for cleanup
    session_temp_dirs = {}

    # Create per-session working directories inside project root so Gradio FileExplorer can access them.
    base_workspace_dir = os.path.join(project_root, "session_workspaces")
    os.makedirs(base_workspace_dir, exist_ok=True)

    def _create_temp_working_dir(session_id: str):
        if session_id in session_temp_dirs:
            return session_temp_dirs[session_id]
        # Use deterministic path inside project to avoid /tmp visibility issues in FileExplorer
        temp_dir = os.path.join(base_workspace_dir, f"ws_{session_id[:8]}")
        os.makedirs(temp_dir, exist_ok=True)
        session_temp_dirs[session_id] = temp_dir
        print(f"[SESSION {session_id}] Created session working dir: {temp_dir}")
        return temp_dir

    def _cleanup_temp_dir(path: str):
        if os.path.exists(path):
            try:
                shutil.rmtree(path, ignore_errors=True)
                print(f"Cleaned temp dir: {path}")
            except Exception as e:
                print(f"Failed to clean temp dir {path}: {e}")

    # Ensure global cleanup at process exit
    atexit.register(lambda: [
        _cleanup_temp_dir(p) for p in list(session_temp_dirs.values())
    ])

    # Helper to derive user id from request (very lightweight). If none, anonymous session id used.
    def _derive_user_id(request: gr.Request | None) -> str:
        """Derive a stable user id prioritizing a persistent cookie.

        Order:
        1. Valid 'hamlet_user_id' cookie (UUID v4 format or UUID.signature)
        2. Fallback hash(IP + UA)
        3. 'anonymous' if request unavailable
        """
        if request is None:
            return "anonymous"
        cookie_id = None
        try:
            cookie_id = request.cookies.get("hamlet_user_id") if request.cookies else None
        except Exception:
            cookie_id = None
        if cookie_id:
            import re
            # Accept either plain UUID v4 or signed variant uuid.hex.signature
            uuid_re = re.compile(r"^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}(\.[0-9a-f]{64})?$")
            if uuid_re.match(cookie_id):
                # If signed form present, strip signature for logical user id
                base_uuid = cookie_id.split('.', 1)[0]
                return base_uuid
        # Fallback: hash IP + user-agent
        import hashlib
        raw = f"{request.client.host}|{request.headers.get('user-agent','')}"  # type: ignore[attr-defined]
        return hashlib.sha256(raw.encode('utf-8')).hexdigest()[:24]

    # Generate / ensure a persistent cookie value for user id
    def _ensure_cookie_user_id(request: gr.Request | None):
        user_id = _derive_user_id(request)
        config_manager.set_user(user_id)
        return user_id
    
    # Removed manual directory setup logic; now per-session temp directories are used.

    # --- ALL EVENT HANDLERS DEFINED FIRST ---

    # Removed: on_working_dir_change (no longer exposed to UI)

    def test_button_click():
        """Simple test function to see if button clicks work."""
        print("DEBUG: Button was clicked!")
        return gr.update(visible=True)

    def show_directory_explorer():
        """Show the directory explorer for folder selection."""
        import os
        print("DEBUG: show_directory_explorer function called!")
        
        # Get current directory as default
        current_dir = os.getcwd()
        print(f"DEBUG: Current directory = {current_dir}")
        
        return (
            gr.update(visible=True),      # dir_explorer_column
            gr.update(value=current_dir), # selected_path_display
            gr.update(value="Button clicked!", visible=True)  # test_label
        )

    def select_quick_directory(dir_type: str):
        """Select a common directory quickly."""
        import os
        
        if dir_type == "current":
            path = os.getcwd()
        elif dir_type == "desktop":
            path = os.path.join(os.path.expanduser("~"), "Desktop")
        elif dir_type == "documents":
            path = os.path.join(os.path.expanduser("~"), "Documents")
        elif dir_type == "home":
            path = os.path.expanduser("~")
        else:
            path = os.getcwd()
        
        return gr.update(value=path)

    def create_directory(path: str):
        """Create a new directory if it doesn't exist."""
        if not path or path.strip() == "":
            return gr.update(value=path), gr.update(value="âŒ Please enter a valid path", visible=True)
        
        try:
            abs_path = os.path.abspath(path.strip())
            if not os.path.exists(abs_path):
                os.makedirs(abs_path, exist_ok=True)
                # Return the path and success status
                return gr.update(value=abs_path), gr.update(value=f"âœ… Created: {abs_path}", visible=True)
            else:
                # Return the path and already exists status
                return gr.update(value=abs_path), gr.update(value=f"ğŸ“ Already exists: {abs_path}", visible=True)
        except Exception as e:
            return gr.update(value=path), gr.update(value=f"âŒ Error creating directory: {str(e)}", visible=True)

    def update_manual_path(path: str):
        """Update the selected path display when user types manually."""
        if path and path.strip():
            abs_path = os.path.abspath(path.strip())
            return gr.update(value=abs_path)
        return gr.update(value="")

    def hide_directory_explorer():
        """Hide the directory explorer."""
        return gr.update(visible=False)

    def confirm_directory_selection(selected_path: str):
        """Confirm the selected directory from the manual input or quick selection."""
        if not selected_path or selected_path.strip() == "":
            return gr.update(value="âŒ No directory selected"), gr.update(visible=False)
        
        try:
            # Convert to absolute path and validate
            abs_path = os.path.abspath(selected_path.strip())
            
            # Create directory if it doesn't exist
            if not os.path.exists(abs_path):
                os.makedirs(abs_path, exist_ok=True)
                print(f"Created directory: {abs_path}")
            
            # Update the working directory input
            return gr.update(value=abs_path), gr.update(visible=False)
            
        except Exception as e:
            return gr.update(value=f"âŒ é”™è¯¯ï¼š{str(e)}"), gr.update(visible=True)

    def on_agent_select(agent_name: str):
        """Handles agent selection dropdown change."""
        if agent_name in ("Create new agent", "åˆ›å»ºæ–°æ™ºèƒ½ä½“"):
            # Build current agent list for sub-agent choices
            all_agent_names = sorted(list(config_manager.get_all_agent_metadata().keys()))
            sub_agent_choices = all_agent_names  # none excluded since we're creating new
            state = {"name": "", "tools": [], "managed_agents": [], "prompt": "", "description": ""}
            return (
                state,            # config_state
                "",              # agent_name_input
                "",              # description input
                [],               # tool selection (hidden internal)
                gr.update(choices=sub_agent_choices, value=[]),  # sub_agent_checkboxes sanitized
                "",              # prompt
                gr.update(visible=True)  # show form
            )
        md = config_manager.get_all_agent_metadata().get(agent_name, {})
        state = {
            "name": agent_name,
            "tools": md.get("tools", []),
            "managed_agents": md.get("sub_agents", []),
            "prompt": md.get("prompt", ""),
            "description": md.get("description", "")
        }
        # Recompute valid sub-agent choices (exclude self to prevent recursion)
        all_agent_names = sorted(list(config_manager.get_all_agent_metadata().keys()))
        sub_agent_choices = [a for a in all_agent_names if a != agent_name]
        valid_selected_subs = [sa for sa in state["managed_agents"] if sa in sub_agent_choices]
        return (
            state,                      # config_state
            state["name"],              # agent_name_input
            state["description"],       # description input
            state["tools"],             # tool selection (hidden internal)
            gr.update(choices=sub_agent_choices, value=valid_selected_subs),  # sanitized sub-agents
            state["prompt"],
            gr.update(visible=True)
        )

    def save_config(name: str, description: str, tools: list, sub_agents: list, prompt: str):
        """Saves the agent's configuration."""
        if not name:
            return gr.update(), gr.update(), gr.update(value="æ™ºèƒ½ä½“çš„åå­—ä¸èƒ½ä¸ºç©º")
        
        all_configs = config_manager.get_all_agent_metadata()
        all_configs[name] = {"prompt": prompt, "description": description, "tools": tools, "sub_agents": sub_agents, "agent_type": "CodeAgent"}
        config_manager.save_agent_configs(all_configs)
        
        # Re-read to ensure persistence and build sorted list for stable UX
        all_agent_names = sorted(list(config_manager.get_all_agent_metadata().keys()))
        # Sub-agent choices should not include the sentinel
        sub_agent_choices = [a for a in all_agent_names if a != name]
        sentinel = "åˆ›å»ºæ–°æ™ºèƒ½ä½“"
        return (
            gr.update(choices=all_agent_names + [sentinel], value=name if name else sentinel),  # Update main selector
            gr.update(choices=sub_agent_choices, value=[sa for sa in sub_agents if sa in sub_agent_choices]),  # Update sub-agent checkbox group
            f"å·²ä¿å­˜ '{name}'"
        )

    def delete_agent(name: str):
        """Delete an existing agent configuration and remove it from any sub-agent lists.

        Returns updates for: agent_selector, sub_agent_checkboxes, launch_status
        Follow-up chain will refresh the form via on_agent_select.
        """
        sentinel = "åˆ›å»ºæ–°æ™ºèƒ½ä½“"
        if not name or name == sentinel or name in ("Create new agent"):
            return gr.update(), gr.update(), "âš ï¸ è¯·é€‰æ‹©è¦åˆ é™¤çš„å·²å­˜åœ¨æ™ºèƒ½ä½“ã€‚"
        all_configs = config_manager.get_all_agent_metadata()
        if name not in all_configs:
            # Nothing to delete
            all_agent_names = sorted(list(all_configs.keys()))
            return (
                gr.update(choices=all_agent_names + [sentinel], value=sentinel),
                gr.update(choices=all_agent_names, value=[]),
                f"âŒ æœªæ‰¾åˆ°æ™ºèƒ½ä½“ '{name}'"
            )
        # Remove the agent
        del all_configs[name]
        # Remove from any sub-agent lists
        changed = False
        for ag_name, meta in all_configs.items():
            subs = meta.get("sub_agents", [])
            if name in subs:
                meta["sub_agents"] = [s for s in subs if s != name]
                changed = True
        if changed:
            config_manager.save_agent_configs(all_configs)
        else:
            # Save after deletion even if no sub-agent change
            config_manager.save_agent_configs(all_configs)
        # Recompute choices
        remaining = sorted(list(all_configs.keys()))
        return (
            gr.update(choices=remaining + [sentinel], value=sentinel),
            gr.update(choices=remaining, value=[]),
            f"ğŸ—‘ï¸ å·²åˆ é™¤æ™ºèƒ½ä½“ '{name}'"
        )

    def launch_agent(state: dict, current_description: str, current_tools: list, current_prompt: str, current_working_dir: str):
        """Launches the agent and switches to the chat UI."""
        if not state.get("name"):
            return gr.update(), gr.update(), None, "âš ï¸ è¯·å…ˆé€‰æ‹©ã€åˆ›å»ºå¹¶ä¿å­˜ä¸€ä¸ªæ™ºèƒ½ä½“ã€‚", gr.update(), gr.update(), gr.update()
        
        # Test API key first
        api_working, api_message = test_api_key()
        if not api_working:
            return gr.update(), gr.update(), None, f"ğŸ”‘ API å¯†é’¥é”™è¯¯ï¼š{api_message}", gr.update(), gr.update()
        
        try:
            agent_name = state["name"]
            print(f"Starting to build agent: {agent_name}")
            print(f"API key test passed: {api_message}")
            print(f"Using working directory: {current_working_dir}")
            
            full_config = config_manager.get_all_agent_metadata().get(agent_name, {})
            
            # Use current UI values instead of saved state
            print(f"Building agent with tools: {current_tools}")
            agent = build_agent(
                name=agent_name,
                system_prompt=current_prompt,  # Append to base system prompt
                tools=current_tools,
                sub_agents=state["managed_agents"],
                agent_type=full_config.get("agent_type", "CodeAgent"),
                working_dir=current_working_dir,
                description=current_description or full_config.get("description", "")
            )
            print(f"Agent {agent_name} built successfully")
            # Override description field if provided
            try:
                agent.description = getattr(agent, 'description', '')
                # Attach session working dir for later file operations
                setattr(agent, '_session_working_dir', current_working_dir)
                # --- Debug prints for system prompt & description ---
                try:
                    sp = getattr(agent, 'system_prompt', '(no system_prompt attribute)')
                except Exception as _e_sp:
                    sp = f"<error retrieving system_prompt: {_e_sp}>"
                try:
                    desc_dbg = getattr(agent, 'description', '(no description attribute)')
                except Exception as _e_desc:
                    desc_dbg = f"<error retrieving description: {_e_desc}>"
                print("[AGENT DEBUG] ================= SYSTEM PROMPT BEGIN ================")
                print(sp)
                print("[AGENT DEBUG] ================= SYSTEM PROMPT END ==================")
                print("[AGENT DEBUG] Description:", desc_dbg if desc_dbg else "(empty description)")
                print(f"[AGENT DEBUG] System prompt length: {len(sp) if isinstance(sp, str) else 'N/A'} chars")
            except Exception:
                pass
            desc_display = current_description or "ï¼ˆæ— æè¿°ï¼‰"
            # Ensure file explorer will point to the working directory
            file_explorer_update = gr.update(root_dir=current_working_dir)
            return (
                gr.update(visible=False),  # hide config page
                gr.update(visible=True),   # show chat page
                agent,                     # agent state
                "âœ… æ™ºèƒ½ä½“å¯åŠ¨æˆåŠŸï¼",  # status (localized)
                # Prefer original display_name (supportsä¸­æ–‡) if present
                gr.update(value=f"## {getattr(agent, 'display_name', agent.name)}"),  # title markdown
                gr.update(value=desc_display),         # description markdown
                file_explorer_update                   # file explorer root refresh
            )
        except Exception as e:
            print(f"Error in launch_agent: {e}")
            import traceback
            traceback.print_exc()
            return gr.update(), gr.update(), None, f"âŒ æ„å»ºæ™ºèƒ½ä½“å¤±è´¥ï¼š{e}", gr.update(), gr.update(), gr.update()

    def handle_upload(file_obj, upload_log: list, working_dir: str):
        """Copies uploaded file to the working directory."""
        if not file_obj:
            return gr.update(visible=False), upload_log, gr.update()
        
        filename = os.path.basename(file_obj.name)
        dest_path = os.path.join(working_dir, filename)
        shutil.copy(file_obj.name, dest_path)
        print(f"File uploaded: {filename} -> {dest_path}")
        
        # Return the status update, updated log, and file explorer refresh
        return (
            gr.update(value=f"å·²ä¸Šä¼  {filename}", visible=True), 
            upload_log + [filename], 
            force_refresh_files(working_dir)
        )

    def force_refresh_files(_=None):
        """Force refresh FileExplorer by tweaking ignore_glob with a random pattern (matches nothing)."""
        dummy_glob = f"__refresh_{int(time.time()*1000)}__"
        return gr.update(ignore_glob=dummy_glob)

    # --- Added helper functions for debug directory listing ---
    # Removed alternate listings & fallback dropdown per user request; rely solely on FileExplorer + ignore_glob refresh.

    # Removed flat file list/dropdown helpers to simplify UI; FileExplorer alone will be used.
    
    # Global variable for file watcher state
    current_watching_dir = None
    
    def periodic_refresh(working_dir_state):
        """Periodic refresh to catch any missed file changes."""
        # This is a reliable catch-all. It runs every 3 seconds.
        if working_dir_state and os.path.exists(working_dir_state):
            print("Periodic refresh triggered.")
            return force_refresh_files(working_dir_state)
        return gr.update()

    # Simplified preview (adapted from agent_conversation_ui.py)
    def show_preview(selection: list, working_dir: str):
        """Return component updates so the appropriate viewer shows the file + a proper download component."""
        hidden = gr.update(visible=False)
        hidden_file = gr.update(value=None, visible=False)
        if not selection:
            return hidden, hidden, hidden, gr.update(value="â¬…ï¸ ç‚¹å‡»æ–‡ä»¶è¿›è¡Œé¢„è§ˆ", visible=True), hidden_file

        # Normalize to list
        if not isinstance(selection, list):
            selection = [selection]
        # Remove duplicates, preserve order
        seen = set()
        selection = [s for s in selection if not (s in seen or seen.add(s))]

        # Sanitize: convert any absolute path under working_dir to relative; ignore paths outside
        sanitized = []
        for p in selection:
            if os.path.isabs(p):
                try:
                    rel = os.path.relpath(p, working_dir)
                    # Disallow escaping via ..
                    if rel.startswith('..'):
                        # Skip anything outside working_dir
                        continue
                    sanitized.append(rel)
                except Exception:
                    continue
            else:
                # Normalize path (remove leading ./)
                norm = p[2:] if p.startswith('./') else p
                sanitized.append(norm)
        selection = sanitized
        if not selection:
            return hidden, hidden, hidden, gr.update(value="âš ï¸ æœªé€‰æ‹©æœ‰æ•ˆçš„æ–‡ä»¶", visible=True), hidden_file
        # If multiple items or any directory selected, just show a summary message (do NOT auto-zip)
        if len(selection) > 1 or any(os.path.isdir(os.path.join(working_dir, p)) for p in selection):
            summary_lines = ["ğŸ“‚ å·²é€‰æ‹©ä»¥ä¸‹é¡¹ç›®ï¼ˆå°šæœªæ‰“åŒ…ï¼Œç‚¹å‡»â€˜æ‰“åŒ…/ä¸‹è½½æ‰€é€‰â€™æŒ‰é’®è¿›è¡Œä¸‹è½½ï¼‰ï¼š"] + [f"- {p}" for p in selection]
            msg = "\n".join(summary_lines)
            return hidden, hidden, hidden, gr.update(value=msg, visible=True), hidden_file

        # Single selection case
        rel_path = selection[0]
        abs_path = os.path.join(working_dir, rel_path)
        if os.path.isdir(abs_path):  # single directory; show message, wait for user to click download
            return hidden, hidden, hidden, gr.update(value=f"ğŸ“ å·²é€‰æ‹©ç›®å½•: {rel_path}ï¼ˆç‚¹å‡»â€˜æ‰“åŒ…/ä¸‹è½½æ‰€é€‰â€™æŒ‰é’®è¿›è¡Œæ‰“åŒ…ä¸‹è½½ï¼‰", visible=True), hidden_file

        download_update = gr.update(value=abs_path, visible=True) if os.path.exists(abs_path) else hidden_file
        ext = os.path.splitext(abs_path)[1].lower()
        # Images
        if ext in {".png", ".jpg", ".jpeg", ".gif", ".bmp", ".webp"}:
            return hidden, gr.update(value=abs_path, visible=True), hidden, hidden, download_update
        # PDF
        if ext == ".pdf":
            return gr.update(value=abs_path, visible=True), hidden, hidden, hidden, download_update
        # Tables
        if ext in {".csv", ".tsv", ".xlsx"}:
            try:
                df = (pd.read_csv if ext != ".xlsx" else pd.read_excel)(abs_path)
                return hidden, hidden, gr.update(value=df, visible=True), hidden, download_update
            except Exception as e:
                return hidden, hidden, hidden, gr.update(value=f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {e}", visible=True), download_update
        # Text fallback
        try:
            with open(abs_path, "r", encoding="utf-8", errors="ignore") as f:
                txt = f.read(20000)
        except Exception as e:
            txt = f"âš ï¸ æ— æ³•æ˜¾ç¤ºæ–‡ä»¶: {e}"
        return hidden, hidden, hidden, gr.update(value=txt, visible=True), download_update

    def interact_with_agent(prompt: str, history: list, agent, uploads: list):
        """Handles the chat interaction with the agent."""
        import gradio as gr
        import os
        prev_cwd = None
        session_dir = getattr(agent, '_session_working_dir', None) if agent else None
        # We avoid global chdir unless really needed; but if user wants relative writes to appear, temporarily chdir
        if session_dir and os.path.isdir(session_dir):
            try:
                prev_cwd = os.getcwd()
                os.chdir(session_dir)
                print(f"[INTERACT] Temporarily switched cwd to {session_dir}")
            except Exception as _e:
                print(f"[INTERACT] Failed to chdir to session dir: {_e}")
        
        if not agent:
            history.append(gr.ChatMessage(role="user", content=prompt))
            history.append(gr.ChatMessage(role="assistant", content="âŒ é”™è¯¯ï¼šæ™ºèƒ½ä½“å°šæœªåŠ è½½ã€‚"))
            yield history
            return

        try:
            history.append(gr.ChatMessage(role="user", content=prompt))
            yield history

            full_prompt = prompt + (f"\n\nFiles provided: {', '.join(uploads)}" if uploads else "")
            
            print(f"Starting agent interaction with prompt: {full_prompt[:50]}...")
            
            # Add timeout handling for network issues
            import signal
            import threading
            import time
            
            # Container to hold results from the agent thread
            result = {"messages": [], "error": None, "completed": False}
            
            def run_agent_with_timeout():
                try:
                    for msg in stream_to_gradio(agent, task=full_prompt, reset_agent_memory=False):
                        result["messages"].append(msg)
                        if len(result["messages"]) > 50:  # Prevent memory issues
                            break
                    result["completed"] = True
                except Exception as e:
                    result["error"] = e
            
            # Run agent in background thread with timeout
            agent_thread = threading.Thread(target=run_agent_with_timeout, daemon=True)
            agent_thread.start()
            
            timeout_seconds = 1200  # Extended overall timeout for slower networks / longer first token latency
            inactivity_grace = 120   # If no new message for this many seconds, warn user
            start_time = time.time()
            last_progress_time = start_time
            message_count = 0
            warned_inactivity = False
            
            while agent_thread.is_alive() and (time.time() - start_time) < timeout_seconds:
                # Process any new messages
                new_data = False
                while message_count < len(result["messages"]):
                    msg = result["messages"][message_count]
                    message_count += 1
                    new_data = True
                    last_progress_time = time.time()
                    if isinstance(msg, gr.ChatMessage):
                        history.append(msg)
                    elif isinstance(msg, str):
                        if history and getattr(history[-1], 'metadata', {}).get("status") == "pending":
                            history[-1].content = msg
                        else:
                            history.append(
                                gr.ChatMessage(role="assistant", content=msg, metadata={"status": "pending"})
                            )
                    yield history

                # Inactivity warning (no new tokens/messages)
                now = time.time()
                if not new_data and (now - last_progress_time) > inactivity_grace and not warned_inactivity:
                    warned_inactivity = True
                    history.append(gr.ChatMessage(
                        role="assistant",
                        content=(
                            "â³ **æ­£åœ¨ç­‰å¾…æ¨¡å‹å“åº”...**\n\nå·²è¶…è¿‡ "
                            f"{int(inactivity_grace)} ç§’æ²¡æœ‰æ–°è¾“å‡ºã€‚å¯èƒ½æ˜¯ï¼š\n"
                            "- ç½‘ç»œè¾ƒæ…¢æˆ–é¦–æ¬¡å“åº”å»¶è¿Ÿ\n"
                            "- æ¨¡å‹ç«¯æ­£åœ¨æ’é˜Ÿ\n"
                            "- å³å°†è§¦å‘è¶…æ—¶ (ä»åœ¨å°è¯•)\n\n"
                            "å¦‚æœæŒç»­æ— å“åº”ï¼Œå¯ç¨åé‡è¯•æˆ–ç®€åŒ–é—®é¢˜ã€‚"
                        ),
                        metadata={"status": "pending"}
                    ))
                    yield history

                time.sleep(0.15)  # Slightly longer sleep reduces CPU load
            
            # Check if we timed out
            if agent_thread.is_alive():
                elapsed = int(time.time() - start_time)
                error_msg = (
                    "â° **è¯·æ±‚è¶…æ—¶**\n\n"
                    f"åœ¨ {elapsed} ç§’å†…æœªå®Œæˆå“åº”ã€‚\n\n"
                    "**å¯èƒ½åŸå› **ï¼š\n"
                    "- é¦–å­—èŠ‚å»¶è¿Ÿè¿‡é•¿ï¼ˆæ¨¡å‹/ç½‘ç»œé˜»å¡ï¼‰\n"
                    "- å½“å‰ç½‘ç»œå‡ºå£é™åˆ¶æˆ–ä¸ç¨³å®š\n"
                    "- API æœåŠ¡ç«¯æ’é˜Ÿæ—¶é—´è¿‡é•¿\n\n"
                    "**å»ºè®®æ“ä½œ**ï¼š\n"
                    "1. æ£€æŸ¥/åˆ‡æ¢ç½‘ç»œæˆ–ä»£ç† (VPN)\n"
                    "2. ç®€åŒ–é—®é¢˜æˆ–å‡å°‘ä¸Šä¸‹æ–‡å†è¯•\n"
                    "3. è‹¥ä»å¤±è´¥ï¼ŒæŸ¥çœ‹æœåŠ¡çŠ¶æ€ï¼šhttps://status.openai.com\n\n"
                    "*(English)* Request timed out after extended waiting. Consider retrying with a simpler query or improved connectivity."
                )
                history.append(gr.ChatMessage(role="assistant", content=error_msg))
                yield history
                return
            
            # Handle any error that occurred
            if result["error"]:
                raise result["error"]
            
            # Process any remaining messages
            while message_count < len(result["messages"]):
                msg = result["messages"][message_count]
                message_count += 1
                
                if isinstance(msg, gr.ChatMessage):
                    history.append(msg)
                elif isinstance(msg, str):
                    if history and getattr(history[-1], 'metadata', {}).get("status") == "pending":
                        history[-1].content = msg
                    else:
                        history.append(
                            gr.ChatMessage(role="assistant", content=msg, metadata={"status": "pending"})
                        )
                yield history

        except Exception as e:
            print(f"Error in interaction: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # Provide specific error messages for common issues
            error_msg = str(e)
            if "timeout" in error_msg.lower() or "connecttimeout" in error_msg.lower():
                error_msg = """ğŸŒ **ç½‘ç»œè¿æ¥é”™è¯¯**

æ— æ³•è¿æ¥åˆ° OpenAI æœåŠ¡å™¨ï¼Œå¯èƒ½åŸå› ï¼š
- ç½‘ç»œä¸ç¨³å®šæˆ–è¢«é˜»æ–­
- é˜²ç«å¢™/å®‰å…¨è½¯ä»¶æ‹¦æˆª
- åœ°åŸŸè®¿é—®é™åˆ¶
- éœ€è¦ä½¿ç”¨ / åˆ‡æ¢ VPN

**å»ºè®®ï¼š**
- æ£€æŸ¥ç½‘ç»œä¸ä»£ç†è®¾ç½®
- æ”¾è¡Œæˆ–æš‚æ—¶å…³é—­é˜²ç«å¢™é˜»æ–­è§„åˆ™
- åœ¨å—é™åœ°åŒºä½¿ç”¨åˆè§„ VPN
- æŸ¥çœ‹æœåŠ¡çŠ¶æ€ï¼šhttps://status.openai.com

*(English)* Network Connection Error: Cannot reach OpenAI servers."""
            elif "api" in error_msg.lower() and "key" in error_msg.lower():
                error_msg += "\n\nğŸ’¡ **API Key Issue:** Check your OPENAI_API_KEY in the .env file"
            
            history.append(gr.ChatMessage(role="assistant", content=f"âŒ **é”™è¯¯ï¼š** {error_msg}"))
            yield history
        finally:
            if prev_cwd:
                try:
                    os.chdir(prev_cwd)
                    print(f"[INTERACT] Restored cwd to {prev_cwd}")
                except Exception as _e:
                    print(f"[INTERACT] Failed to restore cwd: {_e}")
            # After interaction, list session dir for debugging visibility issues
            if session_dir and os.path.isdir(session_dir):
                try:
                    print(f"[INTERACT] Post-interaction dir listing for {session_dir}: {os.listdir(session_dir)}")
                except Exception as e:
                    print(f"[INTERACT] Could not list session dir {session_dir}: {e}")

    def prepare_download(selection: list, working_dir: str):
        """On-demand packaging logic. If multiple files or any directory in selection -> zip now, else return single file.

        Returns a gr.File update (value=path, visible=True) or a status message in text preview if nothing selected.
        """
        if not selection:
            return gr.update(value=None, visible=False), gr.update(value="âš ï¸ æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶æˆ–ç›®å½•", visible=True)
        if not isinstance(selection, list):
            selection = [selection]
        # Deduplicate
        seen = set(); selection = [s for s in selection if not (s in seen or seen.add(s))]
        # Sanitize as in preview
        sanitized = []
        for p in selection:
            if os.path.isabs(p):
                try:
                    rel = os.path.relpath(p, working_dir)
                    if rel.startswith('..'):
                        continue
                    sanitized.append(rel)
                except Exception:
                    continue
            else:
                sanitized.append(p[2:] if p.startswith('./') else p)
        selection = sanitized
        if not selection:
            return gr.update(value=None, visible=False), gr.update(value="âš ï¸ æœªæ‰¾åˆ°å¯æ‰“åŒ…çš„æ–‡ä»¶", visible=True)
        # Any directory OR more than one item -> zip
        multi_or_dir = len(selection) > 1 or any(os.path.isdir(os.path.join(working_dir, p)) for p in selection)
        if multi_or_dir:
            try:
                import zipfile, hashlib, time
                ts = int(time.time()*1000)
                key = "|".join(sorted(selection))
                digest = hashlib.sha1(key.encode('utf-8')).hexdigest()[:10]
                zip_dir = os.path.join(working_dir, "_bundles"); os.makedirs(zip_dir, exist_ok=True)
                zip_path = os.path.join(zip_dir, f"bundle_{digest}_{ts}.zip")
                with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zf:
                    for rel in selection:
                        abs_p = os.path.join(working_dir, rel)
                        if not os.path.exists(abs_p):
                            continue
                        if os.path.isdir(abs_p):
                            for root, dirs, files in os.walk(abs_p):
                                for f in files:
                                    fp = os.path.join(root, f)
                                    arc = os.path.relpath(fp, working_dir)
                                    try: zf.write(fp, arc)
                                    except Exception as ie: print(f"[ZIP] skip {fp}: {ie}")
                        else:
                            try: zf.write(abs_p, rel)
                            except Exception as ie: print(f"[ZIP] skip {abs_p}: {ie}")
                # Schedule deletion after retention period so download can complete
                def _del_later(path=zip_path):
                    try:
                        if os.path.exists(path):
                            os.remove(path)
                            print(f"[BUNDLE] Auto-deleted bundle: {path}")
                    except Exception as de:
                        print(f"[BUNDLE] Failed to auto-delete {path}: {de}")
                try:
                    t = threading.Timer(BUNDLE_RETENTION_SECONDS, _del_later)
                    t.daemon = True
                    t.start()
                    print(f"[BUNDLE] Scheduled deletion in {BUNDLE_RETENTION_SECONDS}s: {zip_path}")
                except Exception as se:
                    print(f"[BUNDLE] Failed to schedule deletion: {se}")
                info_msg = gr.update(value=f"ğŸ” ZIP æ–‡ä»¶å·²ç”Ÿæˆï¼ˆå°†åœ¨ {BUNDLE_RETENTION_SECONDS} ç§’åè‡ªåŠ¨åˆ é™¤ï¼‰", visible=True)
                return gr.update(value=zip_path, visible=True), info_msg
            except Exception as e:
                return gr.update(value=None, visible=False), gr.update(value=f"âš ï¸ æ‰“åŒ…å¤±è´¥: {e}", visible=True)
        # Single file (not directory)
        rel = selection[0]
        abs_path = os.path.join(working_dir, rel)
        if os.path.isdir(abs_path):
            return gr.update(value=None, visible=False), gr.update(value="âš ï¸ ç›®å½•ä¸ºç©ºæˆ–æ— æ³•è®¿é—®", visible=True)
        if not os.path.exists(abs_path):
            return gr.update(value=None, visible=False), gr.update(value="âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨", visible=True)
        return gr.update(value=abs_path, visible=True), gr.update()

    # --- GRADIO UI LAYOUT AND WIRING ---

    with gr.Blocks(title="å·¥ä¸šå·¥ç¨‹å­¦ç§‘å¼•æ“-æ„å»ºä¸“å±æ™ºèƒ½ä½“", fill_height=True) as demo:
        # Use load event to initialize per-user temp directory
        user_id_state = gr.State("")
        session_dir_state = gr.State("")
        
        # --- State Management ---
        config_state = gr.State({"name": "", "tools": [], "managed_agents": [], "prompt": "", "description": ""})
        agent_state = gr.State(None)
        file_uploads_log = gr.State([])
        working_dir_state = gr.State("")  # Will be set on load
        
        # Add a simple periodic refresh timer
        refresh_timer = gr.Timer(value=3.0)  # Check every 3 seconds

        # --- PAGE 1: AGENT CONFIGURATION ---
        with gr.Column(visible=True) as config_page:
            # Inject a small script to set a persistent cookie-based UUID on first visit
            gr.HTML(
                """
<script>
(function(){
    function getCookie(name){
        const m = document.cookie.match(new RegExp('(^| )'+name+'=([^;]+)'));
        return m?decodeURIComponent(m[2]):null;
    }
    if(!getCookie('hamlet_user_id')){
        const uuid = (self.crypto && crypto.randomUUID) ? crypto.randomUUID() : 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c){const r=Math.random()*16|0,v=c==='x'?r:(r&0x3|0x8);return v.toString(16);});
        const oneYear = 60*60*24*365;
        document.cookie = 'hamlet_user_id=' + encodeURIComponent(uuid) + '; Path=/; Max-Age='+oneYear+'; SameSite=Lax';
        // Optional: trigger a soft notice (no auto-reload to avoid loop)
        console.log('Assigned new hamlet_user_id cookie', uuid);
    }
})();
 </script>
"""
            )
        with gr.Column(visible=True) as config_page:
            # é¡¶éƒ¨å¸®åŠ©æŒ‰é’®ä¸å¼¹çª—
            import pathlib
            help_md_path = pathlib.Path("GUI_USAGE_CN.md")
            if help_md_path.exists():
                help_content = help_md_path.read_text(encoding="utf-8")
            else:
                help_content = "### ä½¿ç”¨å¸®åŠ©\næ–‡æ¡£ç¼ºå¤±ï¼šGUI_USAGE_CN.md æœªæ‰¾åˆ°ã€‚"
            with gr.Row():
                gr.Markdown("# å·¥ä¸šå·¥ç¨‹å­¦ç§‘å¼•æ“-æ„å»ºä¸“å±æ™ºèƒ½ä½“")
            # ç›´æ¥ä½¿ç”¨å¯æŠ˜å è¯´æ˜ï¼Œæ— éœ€é¢å¤–æŒ‰é’®ï¼›ç”¨æˆ·ç‚¹å‡»æ ‡é¢˜å³å¯å±•å¼€/æ”¶èµ·
            help_box = gr.Accordion("ğŸ“˜ ä½¿ç”¨è¯´æ˜ï¼ˆç‚¹å‡»å±•å¼€ï¼‰", open=False)
            with help_box:
                help_md = gr.Markdown(help_content)
            user_id_display = gr.Textbox(label="ç”¨æˆ·æ ‡è¯†ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰", interactive=False)
            # Removed directory selection UI entirely
            # gr.Markdown("æ¯ä¸ªä¼šè¯ä¸­æ™ºèƒ½ä½“ä¼šä½¿ç”¨æ–°åˆ›å»ºçš„ä¸´æ—¶å·¥ä½œç©ºé—´ï¼Œå…³é—­é¡µé¢åä¼šè‡ªåŠ¨åˆ é™¤ã€‚")
            gr.Markdown("## é€‰æ‹©è¦å¯åŠ¨æˆ–ä¿®æ”¹çš„æ™ºèƒ½ä½“")
            agent_selector = gr.Dropdown(
                choices=["åˆ›å»ºæ–°æ™ºèƒ½ä½“"] + list(config_manager.get_all_agent_metadata().keys()),
                label="å¯é€‰æ™ºèƒ½ä½“",
                value="åˆ›å»ºæ–°æ™ºèƒ½ä½“"
            )
            launch_status = gr.Textbox(label="çŠ¶æ€", interactive=False, lines=1)
            
            gr.Markdown("## æ™ºèƒ½ä½“é…ç½®ä¿¡æ¯")            
            with gr.Column(visible=False) as config_form:
                agent_name_input = gr.Textbox(label="æ™ºèƒ½ä½“åç§°")
                agent_description_input = gr.Textbox(label="æ™ºèƒ½ä½“æè¿°", lines=3, placeholder="è¯·è¾“å…¥è¯¥æ™ºèƒ½ä½“çš„ç”¨é€”æˆ–ç®€ä»‹â€¦")
                prompt_box = gr.Textbox(lines=5, label="ç³»ç»Ÿæç¤ºè¯", placeholder="æ˜ç¡®è¯¥æ™ºèƒ½ä½“çš„è§’è‰²ã€ç›®æ ‡ã€å¯è°ƒç”¨å·¥å…·ã€ä½•æ—¶è°ƒç”¨å­æ™ºèƒ½ä½“ç­‰â€¦")
                # --- åˆ†ç»„å·¥å…·é€‰æ‹©åŒºï¼ˆæŒ‰å­ç›®å½•æŠ˜å æ˜¾ç¤ºï¼Œæ”¯æŒç»„å…¨é€‰ï¼‰ ---
                def _compute_grouped_tools():
                    cls_map = discover_tools()
                    grouped: dict[str, list[tuple[str,str]]] = {}
                    for tname, cls in cls_map.items():
                        module = getattr(cls, '__module__', '')
                        parts = module.split('.')
                        # group = parts[-1] if len(parts) > 2 and parts[0] == 'src.hamlet.tools' else 'å…¶ä»–'
                        group = parts[-1] if len(parts) > 2 and parts[0] == 'src' else 'å…¶ä»–'
                        desc = getattr(cls, 'description', '') or ''
                        grouped.setdefault(group, []).append((tname, desc))
                    for g in grouped:
                        grouped[g].sort(key=lambda x: x[0])
                    return dict(sorted(grouped.items(), key=lambda kv: kv[0]))

                grouped_tools = _compute_grouped_tools()
                master_components = {}
                tool_components: dict[str, list[gr.Checkbox]] = {}

                # Hidden unified selection state for persistence / saving
                all_tool_names = [t for grp in grouped_tools.values() for t,_ in grp]
                tool_checkboxes = gr.CheckboxGroup(choices=all_tool_names, label="é€‰æ‹©å·¥å…· (å†…éƒ¨)", visible=False)

                gr.Markdown("### å¯é€‰çš„å·¥å…·åˆ†ç»„ï¼ˆå±•å¼€åå¯é€æ¡å‹¾é€‰ï¼Œå·¦ä¾§ä¸ºå·¥å…·å‹¾é€‰ï¼Œå³ä¾§ä¸ºç®€ä»‹ï¼‰")
                for group, tool_list in grouped_tools.items():
                    with gr.Accordion(f"{group}ï¼ˆ{len(tool_list)}ï¼‰å·¥å…·", open=False):
                        master_cb = gr.Checkbox(False, label="å…¨é€‰/å–æ¶ˆæœ¬ç»„", info="å‹¾é€‰åé€‰ä¸­æˆ–æ¸…é™¤æœ¬ç»„æ‰€æœ‰å·¥å…·")
                        per_tool_cbs = []
                        for t, d in tool_list:
                            with gr.Row():
                                cb = gr.Checkbox(False, label=t)
                                # description markdown truncated for readability
                                short = (d or '').strip() if isinstance(d, str) else ''
                                if len(short) > 300:
                                    short = short[:300] + 'â€¦'
                                gr.Markdown(short if short else 'ï¼ˆæ— æè¿°ï¼‰')
                                per_tool_cbs.append(cb)
                        tool_components[group] = per_tool_cbs
                        master_components[group] = master_cb

                def _compute_selected_from_components(current_hidden: list[str], updates: dict[str, bool]):
                    base = set(current_hidden or [])
                    for name, val in updates.items():
                        if val:
                            base.add(name)
                        else:
                            base.discard(name)
                    return sorted(base)

                def toggle_group(master_value: bool, current_selected: list[str], group: str):
                    # Set all tool checkboxes in group to master_value
                    names = [t for t,_ in grouped_tools.get(group, [])]
                    if master_value:
                        new_selected = sorted(set(current_selected or []) | set(names))
                    else:
                        new_selected = [t for t in (current_selected or []) if t not in set(names)]
                    # Return hidden unified update plus each tool checkbox update
                    tool_updates = [gr.update(value=master_value) for _ in names]
                    return [gr.update(value=new_selected)] + tool_updates

                def toggle_single(tool_name: str, tool_value: bool, current_selected: list[str], group: str):
                    if tool_value:
                        new_selected = sorted(set(current_selected or []) | {tool_name})
                    else:
                        new_selected = [t for t in (current_selected or []) if t != tool_name]
                    # Determine master state
                    group_names = [t for t,_ in grouped_tools.get(group, [])]
                    master_state = all(n in new_selected for n in group_names) if group_names else False
                    return gr.update(value=new_selected), gr.update(value=master_state)

                def _sync_wrapper(selected_list: list[str]):
                    """Produce updates for every per-tool checkbox then every master checkbox (order must match wiring)."""
                    selected = set(selected_list or [])
                    updates = []
                    # Per-tool checkboxes (in group order)
                    for group, tool_list in grouped_tools.items():
                        for t,_ in tool_list:
                            updates.append(gr.update(value=(t in selected)))
                    # Master checkboxes
                    for group, tool_list in grouped_tools.items():
                        names = [t for t,_ in tool_list]
                        master_state = all(t in selected for t in names) and len(names) > 0
                        updates.append(gr.update(value=master_state))
                    return updates

                # Bind events for master checkboxes
                for group, master_cb in master_components.items():
                    # Provide hidden textbox carrying group name for arg passing
                    hidden_group = gr.Textbox(value=group, visible=False)
                    names = [t for t,_ in grouped_tools[group]]
                    # Outputs: hidden unified selection + each per-tool checkbox in this group
                    per_tool_cbs = tool_components[group]
                    master_cb.change(
                        toggle_group,
                        [master_cb, tool_checkboxes, hidden_group],
                        [tool_checkboxes] + per_tool_cbs
                    )
                    # Bind each tool checkbox
                    for cb, (tname, _) in zip(per_tool_cbs, grouped_tools[group]):
                        hidden_tool = gr.Textbox(value=tname, visible=False)
                        hidden_group2 = gr.Textbox(value=group, visible=False)
                        cb.change(
                            toggle_single,
                            [hidden_tool, cb, tool_checkboxes, hidden_group2],
                            [tool_checkboxes, master_cb]
                        )
                gr.Markdown("### å¯é€‰çš„å­æ™ºèƒ½ä½“ï¼ˆç”¨æˆ·å…ˆå‰æ„å»ºçš„å…¶ä»–æ™ºèƒ½ä½“ï¼‰")
                sub_agent_checkboxes = gr.CheckboxGroup(choices=list(config_manager.get_all_agent_metadata().keys()))
                with gr.Row():
                    save_button = gr.Button("ä¿å­˜é…ç½®")
                    close_button = gr.Button("å–æ¶ˆ")
                    delete_button = gr.Button("åˆ é™¤æ™ºèƒ½ä½“", variant="stop")
            
            launch_button = gr.Button("å¯åŠ¨æ™ºèƒ½ä½“", variant="primary")

        # --- PAGE 2: CHAT INTERFACE ---
        with gr.Row(visible=False) as chat_page:
            # Left Sidebar: Controls
            with gr.Column(scale=3, min_width=300):
                agent_title_md = gr.Markdown("## ä»£ç åŠ©æ‰‹")
                agent_desc_md = gr.Markdown("ï¼ˆæ— æè¿°ï¼‰")
                # Removedæ˜¾ç¤ºå®é™…æœåŠ¡å™¨è·¯å¾„çš„æ–‡æœ¬æ¡†ä»¥é¿å…æ³„éœ²ç›®å½•ç»“æ„
                file_uploader = gr.File(label="ä¸Šä¼ æ–‡ä»¶", type="filepath")
                upload_status = gr.Textbox(visible=False, interactive=False)
                back_button = gr.Button("â† è¿”å›é…ç½®")

            # Middle Area: Chat
            with gr.Column(scale=6):
                chatbot = gr.Chatbot(
                    label="æ™ºèƒ½ä½“å¯¹è¯",
                    avatar_images=(None, "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/smolagents/mascot_smol.png"),
                    height="calc(100vh - 160px)", # Adjust height for the input box below
                    show_copy_button=True,
                    type="messages"
                )
                with gr.Row():
                    chat_input = gr.Textbox(
                        show_label=False,
                        placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜â€¦",
                        lines=4,
                        scale=8,
                    )
                    submit_button = gr.Button("æäº¤", variant="primary", scale=1, min_width=100)
            # Right Sidebar: Files and Preview (adapted)
            with gr.Column(scale=3, min_width=300, elem_classes="vscode-pane"):
                gr.Markdown("### æ™ºèƒ½ä½“å·¥ä½œç›®å½•")
                gr.Markdown("æ¯æ¬¡å¯¹è¯éƒ½ä¼šä½¿ç”¨ä¸€ä¸ªæ–°çš„ä¸´æ—¶å·¥ä½œç›®å½•ï¼Œæ™ºèƒ½ä½“å¯ä»¥è¯»å†™è¯¥ç›®å½•ä¸‹çš„æ–‡ä»¶ã€‚è¯·æ³¨æ„ï¼Œå…³é—­æˆ–åˆ·æ–°é¡µé¢åç›®å½•ä¼šè¢«è‡ªåŠ¨åˆ é™¤ã€‚")
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°", size="sm")
                file_explorer = gr.FileExplorer(root_dir=".", file_count="multiple", interactive=True, height=220)
                # Removed debug markdown and fallback dropdown
                # Fullscreen overlay container
                gr.HTML("""
<div id='preview-overlay' style='display:none;position:fixed;inset:0;background:rgba(0,0,0,.75);z-index:9999;align-items:center;justify-content:center;'>
    <div id='overlay-content' style='background:#fff;width:95vw;height:95vh;position:relative;overflow:hidden;border-radius:8px;'>
        <span id='overlay-close' style='position:absolute;top:8px;right:16px;font-size:32px;color:#333;cursor:pointer'>&times;</span>
    </div>
</div>
""")
                gr.Markdown("### é¢„è§ˆ <span id='preview_fs' style='cursor:pointer;font-size:0.9em;'>ğŸ—–</span>")
                pdf_preview = PDF(visible=False, interactive=False, elem_classes="preview-box")
                img_preview = gr.Image(interactive=False, visible=False, elem_classes="preview-box")
                table_preview = gr.DataFrame(interactive=False, visible=False, elem_classes="preview-box")
                text_preview = gr.Code(interactive=False, visible=True, lines=20, elem_classes="preview-box")
                # Button to trigger on-demand zipping/downloading
                download_selected_btn = gr.Button("â¬‡ï¸ æ‰“åŒ…/ä¸‹è½½æ‰€é€‰", variant="secondary")
                download_file = gr.File(label="ä¸‹è½½ç»“æœ", visible=False)
                # JS for fullscreen toggle
                demo.load(None, None, None, js="""
() => {
    const btn = document.getElementById('preview_fs');
    const overlay = document.getElementById('preview-overlay');
    const closeBtn = document.getElementById('overlay-close');
    const content = document.getElementById('overlay-content');
    if (!btn || btn.dataset.bound) return; btn.dataset.bound=1;
    function activePreview(){
        return Array.from(document.querySelectorAll('.preview-box')).find(el=>el.offsetParent!==null);
    }
    btn.addEventListener('click', ()=>{
        const box = activePreview(); if(!box) return;
        const placeholder=document.createElement('div'); placeholder.style.display='none';
        box.parentNode.insertBefore(placeholder, box);
        content.innerHTML=''; content.appendChild(box);
        overlay.style.display='flex';
        function close(){ if(placeholder.parentNode) placeholder.parentNode.replaceChild(box, placeholder); overlay.style.display='none'; }
        closeBtn.onclick=close; overlay.onclick=(e)=>{ if(e.target===overlay) close(); };
    });
}
""")
        # --- äº‹ä»¶ç»‘å®š ---
        # First: when selecting an agent, load its config (including hidden unified tool list)
        # Then: synchronize visible grouped checkboxes using the updated hidden list.
        # We build _sync_outputs first so we can chain correctly (patching prior placeholder approach)
        # æ–°ç»“æ„ï¼š_sync_wrapper è¿”å›é¡ºåº = å…¨éƒ¨å·¥å…·å¤é€‰æ¡†(é€ä¸ª) + å…¨éƒ¨ç»„ master å¤é€‰æ¡†
        _sync_outputs = []
        per_tool_flat = []
        for g, tool_list in grouped_tools.items():
            for cb in tool_components[g]:
                per_tool_flat.append(cb)
        _sync_outputs.extend(per_tool_flat)
        for g in grouped_tools.keys():
            _sync_outputs.append(master_components[g])

        agent_selector.change(
            on_agent_select,
            [agent_selector],
            [config_state, agent_name_input, agent_description_input, tool_checkboxes, sub_agent_checkboxes, prompt_box, config_form]
        ).then(
            _sync_wrapper,
            [tool_checkboxes],
            _sync_outputs
        )
        # (Removed placeholder sync rebuilding block â€” outputs are already wired in chain above.)

        save_button.click(
            save_config,
            [agent_name_input, agent_description_input, tool_checkboxes, sub_agent_checkboxes, prompt_box],
            [agent_selector, sub_agent_checkboxes, launch_status]
        )
        delete_button.click(
            delete_agent,
            [agent_name_input],
            [agent_selector, sub_agent_checkboxes, launch_status]
        ).then(
            on_agent_select,
            [agent_selector],
            [config_state, agent_name_input, agent_description_input, tool_checkboxes, sub_agent_checkboxes, prompt_box, config_form]
        )
        close_button.click(lambda: gr.update(visible=False), outputs=[config_form])
        launch_button.click(
            launch_agent, 
            [config_state, agent_description_input, tool_checkboxes, prompt_box, working_dir_state], 
            [config_page, chat_page, agent_state, launch_status, agent_title_md, agent_desc_md, file_explorer]
        )
        file_explorer.change(
            show_preview,
            [file_explorer, working_dir_state],
            [pdf_preview, img_preview, table_preview, text_preview, download_file]
        )
        download_selected_btn.click(
            prepare_download,
            [file_explorer, working_dir_state],
            [download_file, text_preview]
        )
        file_uploader.change(
            handle_upload,
            [file_uploader, file_uploads_log, working_dir_state],
            [upload_status, file_uploads_log, file_explorer]
        ).then(
            force_refresh_files,
            None,
            [file_explorer]
        )

        submit_button.click(
            interact_with_agent,
            [chat_input, chatbot, agent_state, file_uploads_log],
            [chatbot]
        ).then(
            lambda: gr.update(value=""),
            outputs=[chat_input]
        ).then(
            force_refresh_files,
            None,
            [file_explorer]
        )

        chat_input.submit(
            interact_with_agent,
            [chat_input, chatbot, agent_state, file_uploads_log],
            [chatbot]
        ).then(
            lambda: gr.update(value=""),
            outputs=[chat_input]
        ).then(
            force_refresh_files,
            None,
            [file_explorer]
        )

        back_button.click(lambda: (gr.update(visible=True), gr.update(visible=False)), outputs=[config_page, chat_page])

        # æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
        refresh_btn.click(
            force_refresh_files,
            None,
            [file_explorer]
        )

        # å®šæ—¶åˆ·æ–°
        refresh_timer.tick(
            force_refresh_files,  # function accepts optional param, will be called without args
            None,
            [file_explorer]
        )

        # åˆå§‹åŒ–ï¼šä¸ºæ¯ä¸ªå®¢æˆ·ç«¯åˆ›å»ºä¼šè¯ä¸´æ—¶å·¥ä½œç›®å½•
        def _on_app_load(request: gr.Request):  # type: ignore[name-defined]
            user_id = _ensure_cookie_user_id(request)
            session_id = str(uuid.uuid4())
            temp_dir = _create_temp_working_dir(session_id)
            nonlocal current_watching_dir
            current_watching_dir = temp_dir
            file_watcher.start_watching(temp_dir, lambda: print(f"[SESSION {session_id}] FS change."))
            user_agents = sorted(list(config_manager.get_all_agent_metadata().keys()))
            # If the user already has agents, pre-select the first one; otherwise default to sentinel and creation form will appear.
            initial_value = user_agents[0] if user_agents else "åˆ›å»ºæ–°æ™ºèƒ½ä½“"
            selector_update = gr.update(choices=user_agents + ["åˆ›å»ºæ–°æ™ºèƒ½ä½“"], value=initial_value)
            sub_agent_update = gr.update(choices=user_agents, value=[])
            return (
                user_id,
                session_id,
                temp_dir,  # working_dir_state
                gr.update(root_dir=temp_dir),
                gr.update(value=user_id),
                selector_update,
                sub_agent_update
            )

        demo.load(
            _on_app_load,
            inputs=None,
            outputs=[user_id_state, session_dir_state, working_dir_state, file_explorer, user_id_display, agent_selector, sub_agent_checkboxes]
        )
        # Trigger population of form fields (and make config_form visible) based on the initial selector value.
        demo.load(
            on_agent_select,
            inputs=[agent_selector],
            outputs=[config_state, agent_name_input, agent_description_input, tool_checkboxes, sub_agent_checkboxes, prompt_box, config_form]
        )

        def _on_app_unload():
            for d in list(session_temp_dirs.values()):
                _cleanup_temp_dir(d)
        demo.unload(_on_app_unload)

        # Build list button manual trigger
        # Removed fallback list events
        
        # Add cleanup when demo closes (file watcher will auto-cleanup via __del__)
        
    return demo

if __name__ == "__main__":
    app_instance = app()
    print("App created successfully, attempting to launch...")
    app_instance.queue()  # Enable queue for better handling
    app_instance.launch(server_name='0.0.0.0', server_port=4000, share=False)
    # app_instance.launch(server_port=7280, share=False)